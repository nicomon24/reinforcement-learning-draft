{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic CNN using tensorflow\n",
    "DIY CNN using tensorflow to test capabilities on MNIST. First we need to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Train-images: (12000, 28, 28, 1)\n",
      "Train-labels: (12000,)\n",
      "Test: (2000, 28, 28, 1)\n",
      "Test-labels: (2000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntrain_images_flat = []\\nfor image in train_images[:,:,:,0]:\\n    train_images_flat.append(image.flatten())\\ntrain_images_flat = np.array(train_images_flat)\\nprint(train_images_flat.shape)\\n\\ntest_images_flat = []\\nfor image in test_images[:,:,:,0]:\\n    test_images_flat.append(image.flatten())\\ntest_images_flat = np.array(test_images_flat)\\nprint(test_images_flat.shape)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "DATA_DIR = 'MNIST_data/'\n",
    "TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'\n",
    "TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "def _read32(bytestream):\n",
    "    dt = np.dtype(np.uint32).newbyteorder('>')\n",
    "    return np.frombuffer(bytestream.read(4), dtype=dt)\n",
    "\n",
    "def load_images(filename):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        magic = _read32(bytestream)\n",
    "        if magic != 2051:\n",
    "            raise ValueError(\"Invalide magic number in file\")\n",
    "        num_images = _read32(bytestream)[0]\n",
    "        rows = _read32(bytestream)[0]\n",
    "        cols = _read32(bytestream)[0]\n",
    "        buf = bytestream.read(rows * cols * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8)\n",
    "        data = data.reshape(num_images, rows, cols, 1)\n",
    "        return data\n",
    "    \n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = numpy.arange(num_labels) * num_classes\n",
    "    labels_one_hot = numpy.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "def load_labels(filename, one_hot=False):\n",
    "    \"\"\"Extract the labels into a 1D uint8 numpy array [index].\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        magic = _read32(bytestream)\n",
    "        if magic != 2049:\n",
    "            raise ValueError(\n",
    "              'Invalid magic number %d in MNIST label file: %s' %\n",
    "              (magic, filename))\n",
    "        num_items = _read32(bytestream)[0]\n",
    "        buf = bytestream.read(num_items)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "        if one_hot:\n",
    "            return dense_to_one_hot(labels)\n",
    "        return labels\n",
    "    \n",
    "train_images = load_images(DATA_DIR + TRAIN_IMAGES)[:12000]\n",
    "train_labels = load_labels(DATA_DIR + TRAIN_LABELS)[:12000]\n",
    "test_images = load_images(DATA_DIR + TEST_IMAGES)[:2000]\n",
    "test_labels = load_labels(DATA_DIR + TEST_LABELS)[:2000]\n",
    "print(\"Train-images:\", train_images.shape)\n",
    "print(\"Train-labels:\", train_labels.shape)\n",
    "print(\"Test:\", test_images.shape)\n",
    "print(\"Test-labels:\", test_labels.shape)\n",
    "\n",
    "'''\n",
    "train_images_flat = []\n",
    "for image in train_images[:,:,:,0]:\n",
    "    train_images_flat.append(image.flatten())\n",
    "train_images_flat = np.array(train_images_flat)\n",
    "print(train_images_flat.shape)\n",
    "\n",
    "test_images_flat = []\n",
    "for image in test_images[:,:,:,0]:\n",
    "    test_images_flat.append(image.flatten())\n",
    "test_images_flat = np.array(test_images_flat)\n",
    "print(test_images_flat.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADn9JREFUeJzt3X9sXfV5x/HPU8dxlhDauCmeSzMSIC3QsIbtKoCIgImR\npQgpoKqhUVWljDVdC3RsmQTLpjWb2JRNLVXKGJJZsyQVv0oLIn+wVmBV0GrgYbIQfpVfwV0TjE1w\nIYHSxLGf/eGTygXf73XuPfeeaz/vl2T53vOcc8+jk3x87r3fe8/X3F0A4vlA0Q0AKAbhB4Ii/EBQ\nhB8IivADQRF+ICjCDwRF+IGgCD8Q1IxG7mymtfkszWnkLoFQfq13dNgP2WTWrSn8ZrZS0mZJLZL+\nw903pdafpTk62y6qZZcAEnq8e9LrVv2038xaJN0i6dOSzpC0xszOqPbxADRWLa/5l0l6yd33uPth\nSXdJWpVPWwDqrZbwnyjpF+Pu782W/RYzW2dmvWbWO6xDNewOQJ7q/m6/u3e5e8ndS61qq/fuAExS\nLeHfJ2nBuPsfy5YBmAJqCf/jkhab2SIzmynpc5J25NMWgHqreqjP3Y+Y2TWSfqSxob4t7v5Mbp0B\nqKuaxvnd/QFJD+TUC4AG4uO9QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ER\nfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB\nEX4gKMIPBFXTLL1m1ifpoKQRSUfcvZRHU8iPzUj/E7d8ZH5d9//8Xy8sWxuZPZrc9qRTBpP12V+1\nZP21m2aWre0s3Z3cdv/IO8n62fesT9ZP/avHkvVmUFP4M3/k7vtzeBwADcTTfiCoWsPvkh4ysyfM\nbF0eDQFojFqf9i93931mdoKkB83sZ+7+yPgVsj8K6yRplmbXuDsAeanpzO/u+7Lfg5Luk7RsgnW6\n3L3k7qVWtdWyOwA5qjr8ZjbHzOYevS1phaSn82oMQH3V8rS/Q9J9Znb0ce5w9x/m0hWAuqs6/O6+\nR9Kncuxl2mo5fXGy7m2tyfqrF3woWX/3nPJj0u0fTI9X/+RT6fHuIv3Xr+Ym6//ybyuT9Z4z7yhb\ne2X43eS2mwYuTtY/+hNP1qcChvqAoAg/EBThB4Ii/EBQhB8IivADQeXxrb7wRi78g2T9pq23JOsf\nby3/1dPpbNhHkvW/v/mLyfqMd9LDbefec03Z2tx9R5Lbtu1PDwXO7u1J1qcCzvxAUIQfCIrwA0ER\nfiAowg8ERfiBoAg/EBTj/Dloe/7VZP2JXy9I1j/eOpBnO7la339Osr7n7fSlv7ee8v2ytbdG0+P0\nHd/+72S9nqb+F3Yr48wPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZe+NGNI+3dj/bLmrY/prF0JXn\nJusHVqYvr92y+7hk/cmv3nzMPR114/7fT9YfvyA9jj/y5lvJup9b/urufV9LbqpFa55Mr4D36fFu\nHfCh9NzlGc78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUxXF+M9si6VJJg+6+JFvWLuluSQsl9Ula\n7e6/rLSzqOP8lbTM/3CyPvLGULL+yh3lx+qfOX9Lcttl/3xtsn7CLcV9px7HLu9x/q2S3jsR+g2S\nut19saTu7D6AKaRi+N39EUnvPfWskrQtu71N0mU59wWgzqp9zd/h7v3Z7dckdeTUD4AGqfkNPx97\n06DsGwdmts7Mes2sd1iHat0dgJxUG/4BM+uUpOz3YLkV3b3L3UvuXmpVW5W7A5C3asO/Q9La7PZa\nSffn0w6ARqkYfjO7U9Kjkj5hZnvN7CpJmyRdbGYvSvrj7D6AKaTidfvdfU2ZEgP2ORnZ/0ZN2w8f\nmFn1tp/8/LPJ+uu3tqQfYHSk6n2jWHzCDwiK8ANBEX4gKMIPBEX4gaAIPxAUU3RPA6df/0LZ2pVn\npkdk//Ok7mT9gs9enazPvfuxZB3NizM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOP80kJom+42v\nnJ7c9v92vJus33Dj9mT9b1Zfnqz7/36wbG3BPz2a3FYNnD4+Is78QFCEHwiK8ANBEX4gKMIPBEX4\ngaAIPxBUxSm688QU3c1n6E/PTdZv//o3kvVFM2ZVve9Pbr8mWV98W3+yfmRPX9X7nq7ynqIbwDRE\n+IGgCD8QFOEHgiL8QFCEHwiK8ANBVRznN7Mtki6VNOjuS7JlGyV9SdLr2Wob3P2BSjtjnH/q8fOW\nJuvHb9qbrN958o+q3vdpP/6zZP0T/1D+OgaSNPLinqr3PVXlPc6/VdLKCZZ/y92XZj8Vgw+guVQM\nv7s/ImmoAb0AaKBaXvNfa2a7zWyLmc3LrSMADVFt+G+VdLKkpZL6JX2z3Ipmts7Mes2sd1iHqtwd\ngLxVFX53H3D3EXcflXSbpGWJdbvcveTupVa1VdsngJxVFX4z6xx393JJT+fTDoBGqXjpbjO7U9KF\nkuab2V5JX5d0oZktleSS+iR9uY49AqgDvs+PmrR0nJCsv3rFqWVrPddvTm77gQpPTD//yopk/a3l\nbyTr0xHf5wdQEeEHgiL8QFCEHwiK8ANBEX4gKIb6UJjv7U1P0T3bZibrv/LDyfql115X/rHv60lu\nO1Ux1AegIsIPBEX4gaAIPxAU4QeCIvxAUIQfCKri9/kR2+jy9KW7X/5seoruJUv7ytYqjeNXcvPQ\nWcn67Pt7a3r86Y4zPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTj/NGelJcn6C19Lj7Xfdt62ZP38\nWenv1NfikA8n648NLUo/wGh/jt1MP5z5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoiuP8ZrZA0nZJ\nHZJcUpe7bzazdkl3S1ooqU/Sanf/Zf1ajWvGopOS9Zev/GjZ2sYr7kpu+5nj9lfVUx42DJSS9Yc3\nn5Osz9uWvu4/0iZz5j8iab27nyHpHElXm9kZkm6Q1O3uiyV1Z/cBTBEVw+/u/e6+M7t9UNJzkk6U\ntErS0Y9/bZN0Wb2aBJC/Y3rNb2YLJZ0lqUdSh7sf/fzkaxp7WQBgiph0+M3sOEk/kHSdux8YX/Ox\nCf8mnPTPzNaZWa+Z9Q7rUE3NAsjPpMJvZq0aC/7t7n5vtnjAzDqzeqekwYm2dfcudy+5e6lVbXn0\nDCAHFcNvZibpO5Kec/ebxpV2SFqb3V4r6f782wNQL5P5Su95kr4g6Skz25Ut2yBpk6TvmdlVkn4u\naXV9Wpz6Ziz8vWT9rT/sTNav+McfJut//qF7k/V6Wt+fHo579N/LD+e1b/2f5LbzRhnKq6eK4Xf3\nn0oqN9/3Rfm2A6BR+IQfEBThB4Ii/EBQhB8IivADQRF+ICgu3T1JMzp/t2xtaMuc5LZfWfRwsr5m\n7kBVPeXhmn3Lk/Wdt6an6J7//aeT9faDjNU3K878QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUmHH+\nw3+Svkz04b8cStY3nPpA2dqK33mnqp7yMjDybtna+TvWJ7c97e9+lqy3v5kepx9NVtHMOPMDQRF+\nICjCDwRF+IGgCD8QFOEHgiL8QFBhxvn7Lkv/nXvhzHvqtu9b3jwlWd/88Ipk3UbKXTl9zGk3vlK2\ntnigJ7ntSLKK6YwzPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EZe6eXsFsgaTtkjokuaQud99sZhsl\nfUnS69mqG9y9/JfeJR1v7X62Mas3UC893q0DPpT+YEhmMh/yOSJpvbvvNLO5kp4wswez2rfc/RvV\nNgqgOBXD7+79kvqz2wfN7DlJJ9a7MQD1dUyv+c1soaSzJB39zOi1ZrbbzLaY2bwy26wzs14z6x3W\noZqaBZCfSYffzI6T9ANJ17n7AUm3SjpZ0lKNPTP45kTbuXuXu5fcvdSqthxaBpCHSYXfzFo1Fvzb\n3f1eSXL3AXcfcfdRSbdJWla/NgHkrWL4zcwkfUfSc+5+07jlneNWu1xSerpWAE1lMu/2nyfpC5Ke\nMrNd2bINktaY2VKNDf/1SfpyXToEUBeTebf/p5ImGjdMjukDaG58wg8IivADQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUxUt357ozs9cl/XzcovmS9jesgWPTrL01\na18SvVUrz95OcvePTGbFhob/fTs363X3UmENJDRrb83al0Rv1SqqN572A0ERfiCoosPfVfD+U5q1\nt2btS6K3ahXSW6Gv+QEUp+gzP4CCFBJ+M1tpZs+b2UtmdkMRPZRjZn1m9pSZ7TKz3oJ72WJmg2b2\n9Lhl7Wb2oJm9mP2ecJq0gnrbaGb7smO3y8wuKai3BWb2YzN71syeMbO/yJYXeuwSfRVy3Br+tN/M\nWiS9IOliSXslPS5pjbs/29BGyjCzPkkldy98TNjMzpf0tqTt7r4kW/avkobcfVP2h3Oeu1/fJL1t\nlPR20TM3ZxPKdI6fWVrSZZK+qAKPXaKv1SrguBVx5l8m6SV33+PuhyXdJWlVAX00PXd/RNLQexav\nkrQtu71NY/95Gq5Mb03B3fvdfWd2+6CkozNLF3rsEn0VoojwnyjpF+Pu71VzTfntkh4ysyfMbF3R\nzUygI5s2XZJek9RRZDMTqDhzcyO9Z2bppjl21cx4nTfe8Hu/5e6+VNKnJV2dPb1tSj72mq2Zhmsm\nNXNzo0wws/RvFHnsqp3xOm9FhH+fpAXj7n8sW9YU3H1f9ntQ0n1qvtmHB45Okpr9Hiy4n99oppmb\nJ5pZWk1w7Jppxusiwv+4pMVmtsjMZkr6nKQdBfTxPmY2J3sjRmY2R9IKNd/swzskrc1ur5V0f4G9\n/JZmmbm53MzSKvjYNd2M1+7e8B9Jl2jsHf+XJf1tET2U6etkSU9mP88U3ZukOzX2NHBYY++NXCXp\nw5K6Jb0o6SFJ7U3U23clPSVpt8aC1llQb8s19pR+t6Rd2c8lRR+7RF+FHDc+4QcExRt+QFCEHwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8DZI6NXofNrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e61b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# Print the first image as test\n",
    "plt.imshow(train_images[0,:,:,0])\n",
    "plt.show()\n",
    "print(\"Label:\", train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN dense with TF\n",
    "We are going to implement a simple dense NN using tensorflow (not CNN). This won't be very accurate I think. The number of inputs is 784 (28^2). We will use a single hidden layer of variable size. The output is a 10-class softmax representing the estimated digit. We need first to define a layer, then the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    # Bias will turn on/off bias at the activation side, zeros will set all weights to zero initially\n",
    "    def __init__(self, input_size, output_size, f, bias=True, zeros=False):\n",
    "        if zeros:\n",
    "            self.W = np.zeros((input_size, output_size), dtype=np.float32)\n",
    "        else:\n",
    "            self.W = tf.random_normal(shape=(input_size, output_size))\n",
    "        self.W = tf.Variable(self.W)\n",
    "        \n",
    "        self.bias = bias\n",
    "        if bias:\n",
    "            self.b = tf.Variable(np.zeros(output_size).astype(np.float32))\n",
    "        \n",
    "        self.f = f\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if self.bias:\n",
    "            a = tf.matmul(X, self.W) + self.b\n",
    "        else:\n",
    "            a = tf.matmul(X, self.W)\n",
    "        return self.f(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_layer_sizes = []):\n",
    "        self.layers = []\n",
    "        # Add hidden layers\n",
    "        prev_dim = input_size\n",
    "        for layer_size in hidden_layer_sizes:\n",
    "            layer = Layer(prev_dim, layer_size, tf.nn.tanh)\n",
    "            self.layers.append(layer)\n",
    "            prev_dim = layer_size\n",
    "        # Define placeholder\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, input_size), name='X')\n",
    "        self.Y = tf.placeholder(tf.int64, shape=(None, ), name='Y')\n",
    "        # Compute output\n",
    "        Z = self.X\n",
    "        for layer in self.layers:\n",
    "            Z = layer.forward(Z)\n",
    "        self.Y_hat = tf.contrib.layers.softmax(logits=Z)\n",
    "        self.predict_op = tf.argmax(self.Y_hat, axis=-1)\n",
    "        # Train\n",
    "        self.Y_oh = tf.one_hot(indices=tf.cast(self.Y, tf.int32), depth=10)\n",
    "        self.loss = tf.losses.sigmoid_cross_entropy(self.Y_oh, logits=Z)\n",
    "        self.train_op = tf.train.GradientDescentOptimizer(1e-1).minimize(self.loss)\n",
    "        self.correct = tf.equal(self.predict_op, self.Y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct, tf.float32))\n",
    "    \n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        X = np.atleast_2d(X)\n",
    "        Y = np.atleast_1d(Y)\n",
    "        return self.session.run(self.train_op, feed_dict={self.X: X, self.Y: Y})\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        return self.session.run(self.predict_op, feed_dict={self.X : X})\n",
    "    \n",
    "    def get_accuracy(self, X, Y):\n",
    "        return self.session.run(self.accuracy, feed_dict={self.X: X, self.Y: Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnn = Model(784, 10, [100, 10])\\nsession = tf.InteractiveSession()\\ninit = tf.global_variables_initializer()\\nsession.run(init)\\nnn.set_session(session)\\n\\nprint(nn.get_accuracy(test_images_flat, test_labels))\\nfor i in tqdm_notebook(range(1000), desc='Epochs'):\\n    nn.train(train_images_flat, train_labels)\\nprint(nn.get_accuracy(test_images_flat, test_labels))\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests\n",
    "'''\n",
    "nn = Model(784, 10, [100, 10])\n",
    "session = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "nn.set_session(session)\n",
    "\n",
    "print(nn.get_accuracy(test_images_flat, test_labels))\n",
    "for i in tqdm_notebook(range(1000), desc='Epochs'):\n",
    "    nn.train(train_images_flat, train_labels)\n",
    "print(nn.get_accuracy(test_images_flat, test_labels))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will implement a CNN with 1 conv layer, 1 pool layer, 1 dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    \n",
    "    def __init__(self, train_size, batch_size=100, use_tqdm=False):\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "        self.Y = tf.placeholder(tf.int64, shape=(None))\n",
    "        self.is_training= tf.placeholder(tf.bool, shape=(None))\n",
    "        # Convolution\n",
    "        self.c1 = tf.contrib.layers.conv2d(inputs=self.X, num_outputs=32, kernel_size=8)\n",
    "        self.c2 = tf.contrib.layers.conv2d(inputs=self.c1, num_outputs=64, kernel_size=3)\n",
    "        self.p2 = tf.contrib.layers.max_pool2d(inputs=self.c2, kernel_size=2)\n",
    "        self.p2d = tf.contrib.layers.dropout(inputs=self.p2, keep_prob=0.25, is_training=self.is_training[0])\n",
    "        # Flattening\n",
    "        self.flatted = tf.contrib.layers.flatten(inputs=self.p2d)\n",
    "        # Dense\n",
    "        self.d1 = tf.contrib.layers.fully_connected(inputs=self.flatted, num_outputs=128)\n",
    "        self.dropped = tf.contrib.layers.dropout(inputs=self.d1, keep_prob=0.5, is_training=self.is_training[0])\n",
    "        self.d2 = tf.contrib.layers.fully_connected(inputs=self.dropped, num_outputs=10, activation_fn=None)\n",
    "        # Predictions and softmax\n",
    "        self.prediction = tf.argmax(self.d2, axis=1)\n",
    "        self.probabilities = tf.contrib.layers.softmax(logits=self.d2)\n",
    "        # One hot\n",
    "        self.Y_oh = tf.one_hot(indices=tf.cast(self.Y, tf.int32), depth=10)\n",
    "        self.loss = tf.losses.softmax_cross_entropy(self.Y_oh, logits=self.d2)\n",
    "        # Optimization\n",
    "        self.batch_size = batch_size\n",
    "        self.use_tqdm = use_tqdm\n",
    "        batch = tf.Variable(0)\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            1e-3,  # Base learning rate.\n",
    "            batch * self.batch_size,  # Current index into the dataset.\n",
    "            train_size,  # Decay step.\n",
    "            0.95,  # Decay rate.\n",
    "            staircase=True)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss, global_step=batch)\n",
    "        # Accuracy\n",
    "        self.correct = tf.equal(self.prediction, self.Y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct, tf.float32))\n",
    "        \n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.session.run(self.prediction, feed_dict={self.X: X, self.is_training: [False]})\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        if self.use_tqdm:\n",
    "            a = tqdm_notebook(range(0, len(X), self.batch_size), desc='Batches')\n",
    "        else:\n",
    "            a = range(0, len(X), self.batch_size)\n",
    "        for batch_pivot in a:\n",
    "            self.session.run(self.train_op, feed_dict={self.X: X[batch_pivot:batch_pivot+self.batch_size], self.Y: Y[batch_pivot:batch_pivot+self.batch_size], self.is_training: [True]})\n",
    "    \n",
    "    def get_accuracy(self, X, Y):\n",
    "        return self.session.run(self.accuracy, feed_dict={self.X: X, self.Y: Y, self.is_training: [False]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0676667\n",
      "\n",
      "TRAIN ACCURACY: 0.992833\n",
      "TEST ACCURACY: 0.966\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN(train_images.shape[0], batch_size=50, use_tqdm=True)\n",
    "session = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "cnn_model.set_session(session)\n",
    "\n",
    "print(cnn_model.get_accuracy(train_images, train_labels))\n",
    "for i in tqdm_notebook(range(10), desc='Epochs'):\n",
    "    cnn_model.train(train_images, train_labels)\n",
    "print(\"TRAIN ACCURACY:\", cnn_model.get_accuracy(train_images, train_labels))\n",
    "print(\"TEST ACCURACY:\", cnn_model.get_accuracy(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

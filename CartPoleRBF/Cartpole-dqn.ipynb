{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Network in cartpole\n",
    "We are going to use a DQN for cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    display(display_animation(anim, default_mode='once'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-20 14:42:33,566] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"CartPole-v0\").env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create the usual hidden layer (with saved params to copy the NN). I will try to substitute it with a dense layer from TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass HiddenLayer:\\n    \\n    def __init__(self, M1, M2, f=tf.nn.tanh, use_bias=True):\\n        self.W = tf.Variable(tf.random_normal(shape=(M1, M2)))\\n        self.params = [self.W]\\n        self.use_bias = use_bias\\n        if use_bias:\\n            self.b = tf.Variable(np.zeros(M2).astype(np.float32))\\n            self.params.append(self.b)\\n        self.f = f\\n    \\n    def forward(self, X):\\n        if self.use_bias:\\n            a = tf.matmul(X, self.W) + self.b\\n        else:\\n            a = tf.matmul(X, self.W)\\n        return self.f(a)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from dqn_tf import *\n",
    "'''\n",
    "class HiddenLayer:\n",
    "    \n",
    "    def __init__(self, M1, M2, f=tf.nn.tanh, use_bias=True):\n",
    "        self.W = tf.Variable(tf.random_normal(shape=(M1, M2)))\n",
    "        self.params = [self.W]\n",
    "        self.use_bias = use_bias\n",
    "        if use_bias:\n",
    "            self.b = tf.Variable(np.zeros(M2).astype(np.float32))\n",
    "            self.params.append(self.b)\n",
    "        self.f = f\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if self.use_bias:\n",
    "            a = tf.matmul(X, self.W) + self.b\n",
    "        else:\n",
    "            a = tf.matmul(X, self.W)\n",
    "        return self.f(a)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create di DQN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the function to play one episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass DQN:\\n    \\n    def __init__(self, D, K, hidden_layer_sizes, gamma, max_experiences=10000, min_experiences=100, batch_size=32):\\n    \\n        self.K = K\\n        # Create hidden layers\\n        self.layers = []\\n        M1 = D\\n        for M2 in hidden_layer_sizes:\\n            layer = HiddenLayer(M1, M2)\\n            self.layers.append(layer)\\n            M1 = M2\\n        # Final layer with linear f\\n        layer = HiddenLayer(M2, K, lambda x: x)\\n        self.layers.append(layer)\\n        #\\xa0Save params\\n        self.params = []\\n        for layer in self.layers:\\n            self.params += layer.params\\n        #\\xa0Placeholder for input and target\\n        self.X = tf.placeholder(tf.float32, shape=(None, D), name='X')\\n        self.G = tf.placeholder(tf.float32, shape=(None,), name='G')\\n        self.actions = tf.placeholder(tf.int32, shape=(None,), name='actions')\\n        # Forwarding\\n        Z = self.X\\n        for layer in self.layers:\\n            Z = layer.forward(Z)\\n        Y_hat = Z\\n        self.predict_op = Y_hat\\n        # Cost\\n        selected_action_values = tf.reduce_sum(Y_hat * tf.one_hot(self.actions, K), reduction_indices=[1])\\n        cost = tf.reduce_sum(tf.square(self.G - selected_action_values))\\n        self.train_op = tf.train.AdagradOptimizer(10e-3).minimize(cost)\\n        #\\xa0Replay memory\\n        self.experience = {'s' : [], 'a': [], 'r': [], 's2': [], 'done': []}\\n        self.max_experiences = max_experiences\\n        self.min_experiences = min_experiences\\n        self.batch_size = batch_size\\n        self.gamma = gamma\\n        \\n    def set_session(self, session):\\n        self.session = session\\n        \\n    def copy_from(self, other):\\n        ops = []\\n        my_params = self.params\\n        other_params = other.params\\n        for p, q in zip(my_params, other_params):\\n            actual = self.session.run(q)\\n            op = p.assign(actual)\\n            ops.append(op)\\n        self.session.run(ops)\\n    \\n    def predict(self, X):\\n        X = np.atleast_2d(X)\\n        return self.session.run(self.predict_op, feed_dict={self.X : X})\\n    \\n    def train(self, target_network):\\n        #\\xa0First check we have min experiences\\n        if len(self.experience['s']) < self.min_experiences:\\n            return\\n        #\\xa0If we have min exp, we can proceed. Select a batch of indexes\\n        idx = np.random.choice(len(self.experience['s']), size=self.batch_size, replace=False)\\n        states = [self.experience['s'][i] for i in idx]\\n        actions = [self.experience['a'][i] for i in idx]\\n        rewards = [self.experience['r'][i] for i in idx]\\n        next_states = [self.experience['s2'][i] for i in idx]\\n        dones = [self.experience['done'][i] for i in idx]\\n        #\\xa0Calculate targets\\n        next_Q = np.max(target_network.predict(next_states), axis=1)\\n        targets = [r + self.gamma * next_q if not done else r for r, next_q, done in zip(rewards, next_Q, dones)]\\n        #\\xa0Train\\n        self.session.run(self.train_op, feed_dict={\\n            self.X: states,\\n            self.G: targets,\\n            self.actions: actions\\n        })\\n        \\n    def add_experience(self, s, a, r, s2, done):\\n        if len(self.experience['s']) >= self.max_experiences:\\n            self.experience['s'].pop(0)\\n            self.experience['a'].pop(0)\\n            self.experience['r'].pop(0)\\n            self.experience['s2'].pop(0)\\n            self.experience['done'].pop(0)\\n        self.experience['s'].append(s)\\n        self.experience['a'].append(a)\\n        self.experience['r'].append(r)\\n        self.experience['s2'].append(s2)\\n        self.experience['done'].append(done)\\n        \\n    def sample_action(self, X, eps):\\n        if np.random.random() < eps:\\n            return np.random.choice(self.K)\\n        else:\\n            X = np.atleast_2d(X)\\n        return np.argmax(self.predict(X)[0])\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class DQN:\n",
    "    \n",
    "    def __init__(self, D, K, hidden_layer_sizes, gamma, max_experiences=10000, min_experiences=100, batch_size=32):\n",
    "    \n",
    "        self.K = K\n",
    "        # Create hidden layers\n",
    "        self.layers = []\n",
    "        M1 = D\n",
    "        for M2 in hidden_layer_sizes:\n",
    "            layer = HiddenLayer(M1, M2)\n",
    "            self.layers.append(layer)\n",
    "            M1 = M2\n",
    "        # Final layer with linear f\n",
    "        layer = HiddenLayer(M2, K, lambda x: x)\n",
    "        self.layers.append(layer)\n",
    "        # Save params\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "        # Placeholder for input and target\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "        self.G = tf.placeholder(tf.float32, shape=(None,), name='G')\n",
    "        self.actions = tf.placeholder(tf.int32, shape=(None,), name='actions')\n",
    "        # Forwarding\n",
    "        Z = self.X\n",
    "        for layer in self.layers:\n",
    "            Z = layer.forward(Z)\n",
    "        Y_hat = Z\n",
    "        self.predict_op = Y_hat\n",
    "        # Cost\n",
    "        selected_action_values = tf.reduce_sum(Y_hat * tf.one_hot(self.actions, K), reduction_indices=[1])\n",
    "        cost = tf.reduce_sum(tf.square(self.G - selected_action_values))\n",
    "        self.train_op = tf.train.AdagradOptimizer(10e-3).minimize(cost)\n",
    "        # Replay memory\n",
    "        self.experience = {'s' : [], 'a': [], 'r': [], 's2': [], 'done': []}\n",
    "        self.max_experiences = max_experiences\n",
    "        self.min_experiences = min_experiences\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def set_session(self, session):\n",
    "        self.session = session\n",
    "        \n",
    "    def copy_from(self, other):\n",
    "        ops = []\n",
    "        my_params = self.params\n",
    "        other_params = other.params\n",
    "        for p, q in zip(my_params, other_params):\n",
    "            actual = self.session.run(q)\n",
    "            op = p.assign(actual)\n",
    "            ops.append(op)\n",
    "        self.session.run(ops)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        return self.session.run(self.predict_op, feed_dict={self.X : X})\n",
    "    \n",
    "    def train(self, target_network):\n",
    "        # First check we have min experiences\n",
    "        if len(self.experience['s']) < self.min_experiences:\n",
    "            return\n",
    "        # If we have min exp, we can proceed. Select a batch of indexes\n",
    "        idx = np.random.choice(len(self.experience['s']), size=self.batch_size, replace=False)\n",
    "        states = [self.experience['s'][i] for i in idx]\n",
    "        actions = [self.experience['a'][i] for i in idx]\n",
    "        rewards = [self.experience['r'][i] for i in idx]\n",
    "        next_states = [self.experience['s2'][i] for i in idx]\n",
    "        dones = [self.experience['done'][i] for i in idx]\n",
    "        # Calculate targets\n",
    "        next_Q = np.max(target_network.predict(next_states), axis=1)\n",
    "        targets = [r + self.gamma * next_q if not done else r for r, next_q, done in zip(rewards, next_Q, dones)]\n",
    "        # Train\n",
    "        self.session.run(self.train_op, feed_dict={\n",
    "            self.X: states,\n",
    "            self.G: targets,\n",
    "            self.actions: actions\n",
    "        })\n",
    "        \n",
    "    def add_experience(self, s, a, r, s2, done):\n",
    "        if len(self.experience['s']) >= self.max_experiences:\n",
    "            self.experience['s'].pop(0)\n",
    "            self.experience['a'].pop(0)\n",
    "            self.experience['r'].pop(0)\n",
    "            self.experience['s2'].pop(0)\n",
    "            self.experience['done'].pop(0)\n",
    "        self.experience['s'].append(s)\n",
    "        self.experience['a'].append(a)\n",
    "        self.experience['r'].append(r)\n",
    "        self.experience['s2'].append(s2)\n",
    "        self.experience['done'].append(done)\n",
    "        \n",
    "    def sample_action(self, X, eps):\n",
    "        if np.random.random() < eps:\n",
    "            return np.random.choice(self.K)\n",
    "        else:\n",
    "            X = np.atleast_2d(X)\n",
    "        return np.argmax(self.predict(X)[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef play_one(env, model, tmodel, eps, gamma, copy_period, render=False):\\n    observation = env.reset()\\n    done = False\\n    i = 0\\n    frames = []\\n    totalreward = 0\\n    while not done and i < 2000:\\n        if render:\\n            frames.append(env.render(mode = 'rgb_array'))\\n        action = model.sample_action(observation, eps)\\n        prev_observation = observation\\n        observation, reward, done, _ = env.step(action)\\n        totalreward += reward\\n        if done:\\n            reward = -200\\n        # Add experience\\n        model.add_experience(prev_observation, action, reward, observation, done)\\n        model.train(tmodel)\\n        # Increase index and check if copy\\n        i += 1\\n        if i % copy_period == 0:\\n            tmodel.copy_from(model)\\n    return totalreward, frames\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def play_one(env, model, tmodel, eps, gamma, copy_period, render=False):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    i = 0\n",
    "    frames = []\n",
    "    totalreward = 0\n",
    "    while not done and i < 2000:\n",
    "        if render:\n",
    "            frames.append(env.render(mode = 'rgb_array'))\n",
    "        action = model.sample_action(observation, eps)\n",
    "        prev_observation = observation\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        totalreward += reward\n",
    "        if done:\n",
    "            reward = -200\n",
    "        # Add experience\n",
    "        model.add_experience(prev_observation, action, reward, observation, done)\n",
    "        model.train(tmodel)\n",
    "        # Increase index and check if copy\n",
    "        i += 1\n",
    "        if i % copy_period == 0:\n",
    "            tmodel.copy_from(model)\n",
    "    return totalreward, frames\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will init and start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 total reward: 19.0 eps: 1.0 avg reward (last 100): 19.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 19.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 32.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 44.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 54.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 66.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 76.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 86.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 96.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 104.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 117.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 129.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 161.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 176.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 191.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 204.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 213.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 224.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 233.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 247.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 261.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 275.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 296.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 310.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 319.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 328.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 338.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 359.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 369.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 381.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 390.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 400.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 410.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 420.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 435.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 444.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 454.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 464.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 481.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 500.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 512.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 520.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 535.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 562.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 571.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 585.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 598.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 616.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 627.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 648.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 657.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 665.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 674.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 683.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 694.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 712.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 725.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 736.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 750.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 773.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 787.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 806.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 816.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 839.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 856.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 868.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 878.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 892.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 901.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 932.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 944.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 960.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 973.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 986.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1023.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1043.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1064.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1073.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1089.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1100.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1126.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1142.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1151.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1183.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1199.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1217.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1229.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1245.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1258.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1267.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1280.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1302.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1321.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1329.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1347.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1364.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1375.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1385.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1394.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1420.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1429.0\n",
      "episode: 100 total reward: 9.0 eps: 0.099503719021 avg reward (last 100): 14.2376237624\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1438.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1461.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1480.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1493.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1515.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1527.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1538.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1547.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1557.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1584.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1593.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1607.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1616.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1625.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1643.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1655.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1663.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1679.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1700.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1708.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1719.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1729.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1741.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1756.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1765.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1784.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1810.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1836.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1850.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1865.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1878.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1897.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1907.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1924.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1941.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1952.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1962.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1971.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1981.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 1989.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2014.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2035.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2050.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2063.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2072.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2081.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2096.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2111.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2125.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2134.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2157.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2166.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2176.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2185.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2194.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2208.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2219.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2229.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2239.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2260.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2269.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2290.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2304.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2316.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2325.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2334.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2356.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2364.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2373.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2382.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2392.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2403.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2413.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2423.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2432.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2448.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2458.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2467.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2491.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2502.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2533.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2543.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2552.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2560.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2570.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2579.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2589.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2600.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2616.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2625.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2637.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2645.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2653.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2662.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2672.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2682.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2708.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2729.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2748.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2762.0\n",
      "episode: 200 total reward: 8.0 eps: 0.0705345615859 avg reward (last 100): 13.2772277228\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2770.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2779.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2788.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2796.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2810.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2832.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2842.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2850.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2861.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2880.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2897.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2920.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2930.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2940.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2950.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2958.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2981.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 2998.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3008.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3017.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3033.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3042.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3052.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3062.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3073.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3089.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3099.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3119.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3128.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3143.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3153.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3163.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3172.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3182.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3191.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3216.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3240.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3259.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3280.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3297.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3316.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3331.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3343.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3354.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3362.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3382.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3391.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3425.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3442.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3451.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3469.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3479.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3488.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3507.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3523.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3533.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3549.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3557.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3567.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3585.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3615.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3623.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3636.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3647.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3663.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3674.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3715.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3723.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3735.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3748.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3762.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3774.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3792.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3801.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3816.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3832.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3841.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3851.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3870.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3879.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3894.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3904.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3929.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3939.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3951.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3974.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 3987.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4015.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4034.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4043.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4052.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4069.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4079.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4091.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4103.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4112.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4123.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4132.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4145.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4166.0\n",
      "episode: 300 total reward: 19.0 eps: 0.0576390417704 avg reward (last 100): 14.0891089109\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4185.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4194.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4210.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4224.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4233.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4246.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4266.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4276.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4299.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4309.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4318.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4329.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4339.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4348.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4358.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4378.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4388.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4397.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4415.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4424.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4450.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4463.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4479.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4488.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4514.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4533.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4542.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4553.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4575.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4585.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4605.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4614.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4626.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4634.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4652.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4661.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4672.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4688.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4703.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4714.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4730.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4751.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4760.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4771.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4781.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4796.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4805.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4837.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4849.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4857.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4867.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4876.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4886.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4903.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4927.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4936.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4952.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4962.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4971.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4979.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 4989.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5015.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5030.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5049.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5059.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5067.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5084.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5102.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5116.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5125.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5140.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5164.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5175.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5202.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5215.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5223.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5231.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5248.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5261.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5271.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5291.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5316.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5337.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5345.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5364.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5383.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5391.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5407.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5417.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5429.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5441.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5461.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5483.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5493.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5506.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5521.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5539.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5554.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5564.0\n",
      "avg reward for last 100 episodes: 6.01801588995e-31\n",
      "total steps: 5585.0\n",
      "episode: 400 total reward: 19.0 eps: 0.0499376169439 avg reward (last 100): 14.2376237624\n",
      "avg reward for last 100 episodes: 0.19\n",
      "total steps: 5604.0\n",
      "avg reward for last 100 episodes: 0.29\n",
      "total steps: 5614.0\n",
      "avg reward for last 100 episodes: 0.42\n",
      "total steps: 5627.0\n",
      "avg reward for last 100 episodes: 0.51\n",
      "total steps: 5636.0\n",
      "avg reward for last 100 episodes: 0.72\n",
      "total steps: 5657.0\n",
      "avg reward for last 100 episodes: 0.86\n",
      "total steps: 5671.0\n",
      "avg reward for last 100 episodes: 0.95\n",
      "total steps: 5680.0\n",
      "avg reward for last 100 episodes: 1.05\n",
      "total steps: 5690.0\n",
      "avg reward for last 100 episodes: 1.38\n",
      "total steps: 5723.0\n",
      "avg reward for last 100 episodes: 1.54\n",
      "total steps: 5739.0\n",
      "avg reward for last 100 episodes: 1.7\n",
      "total steps: 5755.0\n",
      "avg reward for last 100 episodes: 1.92\n",
      "total steps: 5777.0\n",
      "avg reward for last 100 episodes: 2.04\n",
      "total steps: 5789.0\n",
      "avg reward for last 100 episodes: 2.23\n",
      "total steps: 5808.0\n",
      "avg reward for last 100 episodes: 2.32\n",
      "total steps: 5817.0\n",
      "avg reward for last 100 episodes: 2.44\n",
      "total steps: 5829.0\n",
      "avg reward for last 100 episodes: 2.6\n",
      "total steps: 5845.0\n",
      "avg reward for last 100 episodes: 2.7\n",
      "total steps: 5855.0\n",
      "avg reward for last 100 episodes: 3.0\n",
      "total steps: 5885.0\n",
      "avg reward for last 100 episodes: 3.09\n",
      "total steps: 5894.0\n",
      "avg reward for last 100 episodes: 3.2\n",
      "total steps: 5905.0\n",
      "avg reward for last 100 episodes: 3.38\n",
      "total steps: 5923.0\n",
      "avg reward for last 100 episodes: 3.46\n",
      "total steps: 5931.0\n",
      "avg reward for last 100 episodes: 3.64\n",
      "total steps: 5949.0\n",
      "avg reward for last 100 episodes: 3.74\n",
      "total steps: 5959.0\n",
      "avg reward for last 100 episodes: 3.94\n",
      "total steps: 5979.0\n",
      "avg reward for last 100 episodes: 4.06\n",
      "total steps: 5991.0\n",
      "avg reward for last 100 episodes: 4.24\n",
      "total steps: 6009.0\n",
      "avg reward for last 100 episodes: 4.33\n",
      "total steps: 6018.0\n",
      "avg reward for last 100 episodes: 4.45\n",
      "total steps: 6030.0\n",
      "avg reward for last 100 episodes: 4.6\n",
      "total steps: 6045.0\n",
      "avg reward for last 100 episodes: 4.81\n",
      "total steps: 6066.0\n",
      "avg reward for last 100 episodes: 4.91\n",
      "total steps: 6076.0\n",
      "avg reward for last 100 episodes: 5.01\n",
      "total steps: 6086.0\n",
      "avg reward for last 100 episodes: 5.18\n",
      "total steps: 6103.0\n",
      "avg reward for last 100 episodes: 5.47\n",
      "total steps: 6132.0\n",
      "avg reward for last 100 episodes: 5.62\n",
      "total steps: 6147.0\n",
      "avg reward for last 100 episodes: 5.86\n",
      "total steps: 6171.0\n",
      "avg reward for last 100 episodes: 6.11\n",
      "total steps: 6196.0\n",
      "avg reward for last 100 episodes: 6.22\n",
      "total steps: 6207.0\n",
      "avg reward for last 100 episodes: 6.31\n",
      "total steps: 6216.0\n",
      "avg reward for last 100 episodes: 6.58\n",
      "total steps: 6243.0\n",
      "avg reward for last 100 episodes: 6.68\n",
      "total steps: 6253.0\n",
      "avg reward for last 100 episodes: 6.78\n",
      "total steps: 6263.0\n",
      "avg reward for last 100 episodes: 6.89\n",
      "total steps: 6274.0\n",
      "avg reward for last 100 episodes: 7.0\n",
      "total steps: 6285.0\n",
      "avg reward for last 100 episodes: 7.21\n",
      "total steps: 6306.0\n",
      "avg reward for last 100 episodes: 7.3\n",
      "total steps: 6315.0\n",
      "avg reward for last 100 episodes: 7.51\n",
      "total steps: 6336.0\n",
      "avg reward for last 100 episodes: 7.63\n",
      "total steps: 6348.0\n",
      "avg reward for last 100 episodes: 7.72\n",
      "total steps: 6357.0\n",
      "avg reward for last 100 episodes: 7.92\n",
      "total steps: 6377.0\n",
      "avg reward for last 100 episodes: 8.01\n",
      "total steps: 6386.0\n",
      "avg reward for last 100 episodes: 8.31\n",
      "total steps: 6416.0\n",
      "avg reward for last 100 episodes: 8.41\n",
      "total steps: 6426.0\n",
      "avg reward for last 100 episodes: 8.62\n",
      "total steps: 6447.0\n",
      "avg reward for last 100 episodes: 8.71\n",
      "total steps: 6456.0\n",
      "avg reward for last 100 episodes: 9.03\n",
      "total steps: 6488.0\n",
      "avg reward for last 100 episodes: 9.13\n",
      "total steps: 6498.0\n",
      "avg reward for last 100 episodes: 9.25\n",
      "total steps: 6510.0\n",
      "avg reward for last 100 episodes: 9.35\n",
      "total steps: 6520.0\n",
      "avg reward for last 100 episodes: 9.44\n",
      "total steps: 6529.0\n",
      "avg reward for last 100 episodes: 9.53\n",
      "total steps: 6538.0\n",
      "avg reward for last 100 episodes: 9.65\n",
      "total steps: 6550.0\n",
      "avg reward for last 100 episodes: 9.86\n",
      "total steps: 6571.0\n",
      "avg reward for last 100 episodes: 10.03\n",
      "total steps: 6588.0\n",
      "avg reward for last 100 episodes: 10.14\n",
      "total steps: 6599.0\n",
      "avg reward for last 100 episodes: 10.24\n",
      "total steps: 6609.0\n",
      "avg reward for last 100 episodes: 10.46\n",
      "total steps: 6631.0\n",
      "avg reward for last 100 episodes: 10.56\n",
      "total steps: 6641.0\n",
      "avg reward for last 100 episodes: 10.66\n",
      "total steps: 6651.0\n",
      "avg reward for last 100 episodes: 10.85\n",
      "total steps: 6670.0\n",
      "avg reward for last 100 episodes: 10.96\n",
      "total steps: 6681.0\n",
      "avg reward for last 100 episodes: 11.1\n",
      "total steps: 6695.0\n",
      "avg reward for last 100 episodes: 11.21\n",
      "total steps: 6706.0\n",
      "avg reward for last 100 episodes: 11.33\n",
      "total steps: 6718.0\n",
      "avg reward for last 100 episodes: 11.52\n",
      "total steps: 6737.0\n",
      "avg reward for last 100 episodes: 11.62\n",
      "total steps: 6747.0\n",
      "avg reward for last 100 episodes: 11.72\n",
      "total steps: 6757.0\n",
      "avg reward for last 100 episodes: 11.88\n",
      "total steps: 6773.0\n",
      "avg reward for last 100 episodes: 12.13\n",
      "total steps: 6798.0\n",
      "avg reward for last 100 episodes: 12.22\n",
      "total steps: 6807.0\n",
      "avg reward for last 100 episodes: 12.32\n",
      "total steps: 6817.0\n",
      "avg reward for last 100 episodes: 12.48\n",
      "total steps: 6833.0\n",
      "avg reward for last 100 episodes: 12.56\n",
      "total steps: 6841.0\n",
      "avg reward for last 100 episodes: 12.77\n",
      "total steps: 6862.0\n",
      "avg reward for last 100 episodes: 12.88\n",
      "total steps: 6873.0\n",
      "avg reward for last 100 episodes: 12.97\n",
      "total steps: 6882.0\n",
      "avg reward for last 100 episodes: 13.15\n",
      "total steps: 6900.0\n",
      "avg reward for last 100 episodes: 13.29\n",
      "total steps: 6914.0\n",
      "avg reward for last 100 episodes: 13.55\n",
      "total steps: 6940.0\n",
      "avg reward for last 100 episodes: 13.65\n",
      "total steps: 6950.0\n",
      "avg reward for last 100 episodes: 13.91\n",
      "total steps: 6976.0\n",
      "avg reward for last 100 episodes: 14.21\n",
      "total steps: 7006.0\n",
      "avg reward for last 100 episodes: 14.3\n",
      "total steps: 7015.0\n",
      "avg reward for last 100 episodes: 14.41\n",
      "total steps: 7026.0\n",
      "avg reward for last 100 episodes: 14.59\n",
      "total steps: 7044.0\n",
      "avg reward for last 100 episodes: 14.7\n",
      "total steps: 7055.0\n",
      "avg reward for last 100 episodes: 14.93\n",
      "total steps: 7078.0\n",
      "avg reward for last 100 episodes: 15.03\n",
      "total steps: 7088.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLAkXdDOzJFzQzcyScEE3M0vCBd3MLIk3g/Ge4gTHsuMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a39da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gamma = 0.99\n",
    "copy_period = 50\n",
    "\n",
    "D = len(env.observation_space.sample())\n",
    "K = env.action_space.n\n",
    "sizes = [200,200]\n",
    "model = DQN(D, K, sizes, gamma)\n",
    "tmodel = DQN(D, K, sizes, gamma)\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.InteractiveSession()\n",
    "session.run(init)\n",
    "model.set_session(session)\n",
    "tmodel.set_session(session)\n",
    "\n",
    "N = 500\n",
    "totalrewards = np.empty(N)\n",
    "costs = np.empty(N)\n",
    "for n in range(N):\n",
    "    eps = 1.0/np.sqrt(n+1)\n",
    "    totalreward = play_one(env, model, tmodel, eps, gamma, copy_period)\n",
    "    totalrewards[n] = totalreward\n",
    "    if n % 100 == 0:\n",
    "        print(\"episode:\", n, \"total reward:\", totalreward, \"eps:\", eps, \"avg reward (last 100):\", totalrewards[max(0, n-100):(n+1)].mean())\n",
    "\n",
    "    print(\"avg reward for last 100 episodes:\", totalrewards[-100:].mean())\n",
    "    print(\"total steps:\", totalrewards.sum())\n",
    "\n",
    "plt.plot(totalrewards)\n",
    "plt.title(\"Rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
